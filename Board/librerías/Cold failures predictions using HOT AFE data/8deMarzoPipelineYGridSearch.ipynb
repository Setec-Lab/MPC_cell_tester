{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6329ee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e9a24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Expand jupyter cell to complete view in high resolution monitor\n",
    "#from IPython.core.display import display, HTML\n",
    "#display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45697c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "315    1\n",
      "316    1\n",
      "317    1\n",
      "318    1\n",
      "319    1\n",
      "Name: Y, Length: 320, dtype: int64\n",
      "     Gen  TEST_STATUS_LANE  PRE_CURSOR  CURSOR  POST_CURSOR  \\\n",
      "0      1                 1           0      20            4   \n",
      "1      2                 1           0      20            4   \n",
      "2      1                 1           0      20            4   \n",
      "3      3                 1           3      18            3   \n",
      "4      4                 1           3      18            3   \n",
      "..   ...               ...         ...     ...          ...   \n",
      "315    1                 1           0      20            4   \n",
      "316    3                 1           3      18            3   \n",
      "317    4                 1           3      18            3   \n",
      "318    2                 1           0      20            4   \n",
      "319    2                 1           0      20            4   \n",
      "\n",
      "     DCC2_PCODE_STATUS  DCC2_NCODE_STATUS  RCOMP_PFET_CODE  RCOMP_NFET_CODE  \\\n",
      "0                    8                  8               15               19   \n",
      "1                    8                  8               15               19   \n",
      "2                    6                  8               15               19   \n",
      "3                    6                 10               14               19   \n",
      "4                    6                 10               14               19   \n",
      "..                 ...                ...              ...              ...   \n",
      "315                  6                 10               13               19   \n",
      "316                  1                  6               17               20   \n",
      "317                  2                  6               17               20   \n",
      "318                  6                  6               15               19   \n",
      "319                  6                  7               20               22   \n",
      "\n",
      "     CTLE12_POSTLB  ...  IDACF  TFR  DFEVG  LFEQ  DDFE_EN  IDACT  RXRCOMP  \\\n",
      "0               31  ...     22   17     12     2        0    128       22   \n",
      "1               31  ...     24   17     12     2        0    125       20   \n",
      "2               30  ...     25   18     14     3        0    128       20   \n",
      "3               33  ...     22   15     14     2        0    125       20   \n",
      "4               37  ...     24   15     14     2        1    125       19   \n",
      "..             ...  ...    ...  ...    ...   ...      ...    ...      ...   \n",
      "315             33  ...     23   16     12     3        0    127       12   \n",
      "316             31  ...     22   16     14     3        0    125       12   \n",
      "317             34  ...     24   16     14     3        1    120       24   \n",
      "318             32  ...     23   16     13     3        0    127       12   \n",
      "319             31  ...     21   16     14     3        0    125       12   \n",
      "\n",
      "     DCO_RTUNE  IDACC  VCCDCO_POSTLB  \n",
      "0           19     14             23  \n",
      "1           16     13             24  \n",
      "2           21     12             23  \n",
      "3           14     14             22  \n",
      "4           11     13             23  \n",
      "..         ...    ...            ...  \n",
      "315         14     13             23  \n",
      "316         13     14             23  \n",
      "317         11     13             23  \n",
      "318         17     13             23  \n",
      "319         15     14             23  \n",
      "\n",
      "[320 rows x 66 columns]\n",
      "0         0\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "         ..\n",
      "136379    0\n",
      "136380    0\n",
      "136381    0\n",
      "136382    0\n",
      "136383    0\n",
      "Name: Y, Length: 136384, dtype: int64\n",
      "        Gen  TEST_STATUS_LANE  PRE_CURSOR  CURSOR  POST_CURSOR  \\\n",
      "0         1                 1           0      20            4   \n",
      "1         1                 1           0      20            4   \n",
      "2         1                 1           0      20            4   \n",
      "3         1                 1           0      20            4   \n",
      "4         1                 1           0      20            4   \n",
      "...     ...               ...         ...     ...          ...   \n",
      "136379    4                 1           3      18            3   \n",
      "136380    4                 1           3      18            3   \n",
      "136381    4                 1           3      18            3   \n",
      "136382    4                 1           3      18            3   \n",
      "136383    4                 1           3      18            3   \n",
      "\n",
      "        DCC2_PCODE_STATUS  DCC2_NCODE_STATUS  RCOMP_PFET_CODE  \\\n",
      "0                       8                  8               15   \n",
      "1                       8                  8               15   \n",
      "2                       8                  8               15   \n",
      "3                       8                  8               15   \n",
      "4                       8                  8               15   \n",
      "...                   ...                ...              ...   \n",
      "136379                  6                  8               18   \n",
      "136380                  6                  8               18   \n",
      "136381                  6                  8               18   \n",
      "136382                  6                  8               18   \n",
      "136383                  6                  8               18   \n",
      "\n",
      "        RCOMP_NFET_CODE  CTLE12_POSTLB  ...  IDACF  TFR  DFEVG  LFEQ  DDFE_EN  \\\n",
      "0                    19             31  ...     23   17     15     2        0   \n",
      "1                    19             31  ...     24   17     14     2        0   \n",
      "2                    19             30  ...     21   17     12     2        0   \n",
      "3                    19             29  ...     21   17     12     2        0   \n",
      "4                    19             31  ...     23   17     13     2        0   \n",
      "...                 ...            ...  ...    ...  ...    ...   ...      ...   \n",
      "136379               21             29  ...      6   16     15     3        1   \n",
      "136380               21             25  ...     11   16     14     3        1   \n",
      "136381               21             33  ...     25   16     14     3        1   \n",
      "136382               21             31  ...     24   16     14     3        1   \n",
      "136383               21             30  ...     25   16     16     3        0   \n",
      "\n",
      "        IDACT  RXRCOMP  DCO_RTUNE  IDACC  VCCDCO_POSTLB  \n",
      "0         127       22         23     14             23  \n",
      "1         126       22         17     12             23  \n",
      "2         128       22         14     14             23  \n",
      "3         128       22         16     14             23  \n",
      "4         128       22         17     13             23  \n",
      "...       ...      ...        ...    ...            ...  \n",
      "136379    129       12         13     19             23  \n",
      "136380    128       12         12     18             23  \n",
      "136381    124       12         13     11             23  \n",
      "136382    123       12         16     12             23  \n",
      "136383    125       12         14     13             23  \n",
      "\n",
      "[136384 rows x 66 columns]\n",
      "There are 0 categorical features: \n",
      "\n",
      "There are 66 numerical features: \n",
      "\n",
      "Cantidad de muestras originales de entrenamiento\n",
      "0    134568\n",
      "1      1816\n",
      "Name: Y, dtype: int64\n",
      "Cantidad de muestras reservadas para testeo de clase 1\n",
      "320\n",
      "Cantidad de muestras por clase después de realizar oversampling\n",
      "0    134568\n",
      "1     20185\n",
      "Name: Y, dtype: int64\n",
      "Cantidad de muestras por clase después de realizar undersampling\n",
      "0    67283\n",
      "1    20185\n",
      "Name: Y, dtype: int64\n",
      "Split de datos de entrenamiento y testeo\n",
      "\tTrain:  61227\n",
      "\tTest:  26241\n",
      "Split de datos de entrenamiento y testeo al agregar datos de clase 1 nuevos\n",
      "\tTrain:  61227\n",
      "\tTest:  26561\n"
     ]
    }
   ],
   "source": [
    "# https://towardsdatascience.com/how-to-use-sklearn-pipelines-for-ridiculously-neat-code-a61ab66ca90d \n",
    "# Pipeline and gridsearch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from numpy import genfromtxt\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import RobustScaler, Normalizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample\n",
    "import imblearn\n",
    "from imblearn.under_sampling import (ClusterCentroids, RandomUnderSampler, OneSidedSelection,  NeighbourhoodCleaningRule, InstanceHardnessThreshold, AllKNN, NearMiss)\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTEN, SMOTE, ADASYN, BorderlineSMOTE\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import statsmodels.api as sm\n",
    "import pylab\n",
    "from scipy import stats\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "                                                                            # df refers to data frame\n",
    "                                                                            # add here the new data extracted for validation purposes\n",
    "#df_raw_test = pd.read_csv('C:\\\\Users\\\\kevinmor\\\\OneDrive - Intel Corporation\\\\Desktop\\\\Full Time\\\\AFE AI Assesment\\\\CSE\\\\testdataset.csv')\n",
    "                                                                            # volume raw data for further prediction model testing purposes\n",
    "\n",
    "df = pd.read_csv('C:/Users/kagomezv/OneDrive - Intel Corporation/Desktop/Cold failures predictions using HOT AFE data/afe_cold_5430_train_minus15.csv')\n",
    "                                                                            # dataset with unseen class 1 examples\n",
    "df_test = pd.read_csv('C:/Users/kagomezv/OneDrive - Intel Corporation/Desktop/Cold failures predictions using HOT AFE data/afe_cold_5430_test_15.csv')\n",
    "\n",
    "                                                                            # there is pending to automate column removal, for example when one column has just one value (it does not contribute with valuable information)\n",
    "\n",
    "                                                                            # split features and output of test dataset\n",
    "y_t = df_test.Y\n",
    "X_t = df_test.drop('Y',axis=1)\n",
    "print(y_t)\n",
    "print(X_t)\n",
    "                                                                            # split features and output of training dataset\n",
    "y = df.Y\n",
    "X = df.drop('Y',axis=1)\n",
    "print(y)\n",
    "print(X)\n",
    "\n",
    "                                                                            # X and y contain original dataset\n",
    "                                                                            # confirm that there are not categorical features          \n",
    "categorical_features = X.select_dtypes(exclude='number').columns.tolist()\n",
    "print(f'There are {len(categorical_features)} categorical features:', '\\n')\n",
    "                                                                            # obtain numerical features\n",
    "numerical_features = X.select_dtypes(include='number').columns.tolist()\n",
    "print(f'There are {len(numerical_features)} numerical features:', '\\n')\n",
    "#print(numerical_features)\n",
    "                                                                            # X_cc and y_cc will contain preprocessed data\n",
    "                                                                            # u refers to unprocessed \n",
    "X_ccu, y_cc = X, y\n",
    "print(\"Cantidad de muestras originales de entrenamiento\")\n",
    "print(df['Y'].value_counts())  \n",
    "\n",
    "\n",
    "print(\"Cantidad de muestras reservadas para testeo de clase 1\")\n",
    "print(len(X_t))\n",
    "\n",
    "                                                                            # oversampling or boostering    \n",
    "                                                                            # https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/\n",
    "                                                                            # the minority class would have, in this case, the sampling_strategy*100 percentaje of the majority class examples\n",
    "                                                                            # https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html#imblearn.over_sampling.RandomOverSampler.fit_resample\n",
    "                                                                        \n",
    "# Minority class proportion\n",
    "ONm= 15\n",
    "# Mayority class proportion\n",
    "ONM= 100\n",
    "ratioOverSampling= ONm/ONM\n",
    "\n",
    "# SMOTE and ADASYN generate new samples in by interpolation\n",
    "# When dealing with a mixed of continuous and categorical features, SMOTENC is the only method which can handle this case.\n",
    "# ADASYN will focus on the samples which are difficult to classify with a nearest-neighbors rule while regular SMOTE will not make any distinction\n",
    "# https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTEN.html#imblearn.over_sampling.SMOTEN\n",
    "# number of nearest neighbours to used to construct synthetic samples\n",
    "# https://imbalanced-learn.org/stable/auto_examples/over-sampling/plot_comparison_over_sampling.html\n",
    "oversamplers = [RandomOverSampler(sampling_strategy=ratioOverSampling), SMOTEN(random_state=17, sampling_strategy=ratioOverSampling, n_jobs=-1, k_neighbors=5), BorderlineSMOTE(random_state=0, kind=\"borderline-1\") ]\n",
    "oversample = oversamplers[0]\n",
    "                                                                            # fit and apply the transform\n",
    "X_ccu, y_cc = oversample.fit_resample(X_ccu, y_cc)\n",
    "print(\"Cantidad de muestras por clase después de realizar oversampling\")\n",
    "print(y_cc.value_counts())\n",
    "\n",
    "#Under-sampling: Cluster Centroids\n",
    "# Minority class proportion\n",
    "Nm= 30\n",
    "# Mayority class proportion\n",
    "NM= 100\n",
    "ratioUnderSampling= Nm/NM\n",
    "\n",
    "# Compare undersamplers\n",
    "# https://imbalanced-learn.org/stable/auto_examples/under-sampling/plot_comparison_under_sampling.html#sphx-glr-auto-examples-under-sampling-plot-comparison-under-sampling-py\n",
    "samplers= [ClusterCentroids(sampling_strategy=ratioUnderSampling), \n",
    "           InstanceHardnessThreshold(estimator=LogisticRegression(),random_state=0),\n",
    "           OneSidedSelection(random_state=0), \n",
    "           NeighbourhoodCleaningRule(),\n",
    "           AllKNN(allow_minority=True),\n",
    "           NearMiss(version=1, sampling_strategy=ratioUnderSampling, n_jobs=-1), \n",
    "           NearMiss(version=2, sampling_strategy=ratioUnderSampling, n_jobs=-1), \n",
    "           NearMiss(version=3, n_neighbors_ver3=3, n_jobs=-1)]\n",
    "                                                                            # undersampling\n",
    "                                                                            # https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/\n",
    "#undersample = RandomUnderSampler(sampling_strategy=1)\n",
    "                                                                            # fit and apply the transform\n",
    "#X_cc, y_cc = undersample.fit_resample(X_cc, y_cc)\n",
    "cc = samplers[5]\n",
    "X_ccu, y_cc = cc.fit_resample(X_ccu, y_cc)\n",
    "                                                                            # summarize class distribution\n",
    "print(\"Cantidad de muestras por clase después de realizar undersampling\")\n",
    "print(y_cc.value_counts())\n",
    "                                                                            # Combining over/under-sampling can result in improved overall performance compared to performing one or the other techniques in isolation.\n",
    "                                                                            # split data into train and test subsets\n",
    "                                                                            # altough class 0 test examples are new to the AI models that are going to be trained, class 1 examples are not new, this because of the oversampling strategy followed.\n",
    "                                                                            # due to the reproduction of class 1 examples, at test dataset, there are \"seen\" examples for the neuronal networks, so there are needed real new examples, this is the\n",
    "                                                                            # intend of X_t examples.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ccu, y_cc, train_size=0.7, random_state=17)\n",
    "print(\"Split de datos de entrenamiento y testeo\")\n",
    "print(\"\\tTrain: \", len(X_train))\n",
    "print(\"\\tTest: \", len(X_test))\n",
    "                                                                            # add 321 (15 % of original class 1) unseen class 1 examples\n",
    "X_test=np.append(X_test, X_t, axis=0)\n",
    "y_test=np.append(y_test, y_t, axis=0)\n",
    "print(\"Split de datos de entrenamiento y testeo al agregar datos de clase 1 nuevos\")\n",
    "print(\"\\tTrain: \", len(X_train))\n",
    "print(\"\\tTest: \", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de6f1cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0. ,  0. , ...,  0.2,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. , ..., -1.2, -0.5,  0. ],\n",
       "       [ 0. ,  0. ,  0. , ...,  0.6, -0.5,  0. ],\n",
       "       ...,\n",
       "       [-0.5,  0. ,  0. , ...,  1. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. , ...,  0. , -0.5,  0. ],\n",
       "       [ 0.5,  0. ,  1. , ..., -0.8,  0. ,  0. ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                                                            # https://towardsdatascience.com/how-to-use-sklearn-pipelines-for-ridiculously-neat-code-a61ab66ca90d\n",
    "                                                            # Define preprocessing for data\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    ('scale', RobustScaler())\n",
    "    ])\n",
    "                                                            # pipeline objects have fit and transform methods\n",
    "numeric_pipeline.fit_transform(X_train.select_dtypes(include='number'))\n",
    "                                                            # define scaler for numerical features                                                            \n",
    "full_processor = ColumnTransformer(transformers=[\n",
    "    ('number', numeric_pipeline, numerical_features)\n",
    "    ])\n",
    "# apply transformation\n",
    "full_processor.fit_transform(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69ea227",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearchCV for tunning model\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# https://towardsdatascience.com/binary-classification-xgboost-hyperparameter-tuning-scenarios-by-non-exhaustive-grid-search-and-c261f4ce098d\n",
    "# https://xgboost.readthedocs.io/en/stable/tutorials/param_tuning.html\n",
    "# https://blog.cambridgespark.com/hyperparameter-tuning-in-xgboost-4ff9100a3b2f\n",
    "# https://machinelearningmastery.com/xgboost-for-imbalanced-classification/\n",
    "# https://xgboost-clone.readthedocs.io/en/latest/parameter.html#learning-task-parameters\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "# https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/\n",
    "\n",
    "#  scale_pos_weight is the ratio of number of negative class to the positive class (0.7)\n",
    "# \"subsample\" is the fraction of the training samples (randomly selected) that will be used to train each tree.\n",
    "# \"colsample_by_tree\" is the fraction of features (randomly selected) that will be used to train each tree.\n",
    "# \"colsample_bylevel\" is the fraction of features (randomly selected) that will be used in each node to train each tree.\n",
    "# A smaller min_child_weight allows the algorithm to create children that correspond to fewer samples, thus allowing for more complex trees, but again, more likely to overfit.\n",
    "\n",
    "# 3888 experiments\n",
    "param_grid = {'gamma': [0.1, 0.25, 0.35],\n",
    "              'eta': [0.15, 0.25, 0.38],\n",
    "              'max_depth': [35, 40, 45],\n",
    "              'n_estimators': [50, 100,200],\n",
    "              'reg_alpha': [0.05, 0.1, 0.15],\n",
    "              'reg_lambda': [0.05, 0.1, 0.15],\n",
    "              'colsample_bytree': [0.90, 0.95, 1],\n",
    "              'colsample_bylevel': [0.95, 1],\n",
    "              'min_child_weight': [5, 10],\n",
    "              'scale_pos_weight': [0.72, 0.75, 0.8]}\n",
    "\n",
    "\n",
    "\n",
    "# Init classifier\n",
    "xgb_cl = xgb.XGBClassifier(objective=\"binary:logistic\")\n",
    "\n",
    "# Init Grid Search\n",
    "grid_cv = GridSearchCV(xgb_cl, param_grid, n_jobs=-1, cv=3, scoring=\"f1\")\n",
    "\n",
    "# Fit\n",
    "_ = grid_cv.fit(X_train, y_train)\n",
    "\n",
    "print('Best score:', abs(grid_cv.best_score_))\n",
    "print('Best alpha:', grid_cv.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196ff11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill with the best parameters found\n",
    "\n",
    "xgb_cl = xgb.XGBClassifier()\n",
    "final_lasso_pipe = Pipeline(steps=[\n",
    "    ('preprocess', full_processor),\n",
    "    ('model', lasso)\n",
    "])\n",
    "\n",
    "_ = final_lasso_pipe.fit(X_train, y_train)\n",
    ">>> preds = final_lasso_pipe.predict(X_valid)\n",
    "# Fit\n",
    "xgb_cl.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "resultXGB = xgb_cl.predict(X_test)\n",
    "\n",
    "# Score\n",
    "#accuracy_score(y_test, preds)\n",
    "print(\"Accuracy for XGBoost: \" + str(accuracy_score(resultXGB, y_test)))\n",
    "print(\"F1_Score for XGBoost: \" + str(f1_score(resultXGB, y_test)))\n",
    "print(\"Precision_Score for XGBoost: \" + str(precision_score(resultXGB, y_test)))\n",
    "print(\"Recall_Score for XGBoost: \" + str(recall_score(resultXGB, y_test)))\n",
    "\n",
    "cm = confusion_matrix(y_test, resultXGB)\n",
    "%matplotlib inline\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c97741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/beginners-guide-to-xgboost-for-classification-problems-50f75aac5390\n",
    "#https://towardsdatascience.com/getting-started-with-xgboost-in-scikit-learn-f69f5f470a97\n",
    "# Pipeline: https://towardsdatascience.com/how-to-use-sklearn-pipelines-for-ridiculously-neat-code-a61ab66ca90d\n",
    "\n",
    "\n",
    "xgb_cl = xgb.XGBClassifier()\n",
    "\n",
    "\n",
    "# Fit\n",
    "xgb_cl.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "resultXGB = xgb_cl.predict(X_test)\n",
    "\n",
    "# Score\n",
    "#accuracy_score(y_test, preds)\n",
    "print(\"Accuracy for XGBoost: \" + str(accuracy_score(resultXGB, y_test)))\n",
    "print(\"F1_Score for XGBoost: \" + str(f1_score(resultXGB, y_test)))\n",
    "print(\"Precision_Score for XGBoost: \" + str(precision_score(resultXGB, y_test)))\n",
    "print(\"Recall_Score for XGBoost: \" + str(recall_score(resultXGB, y_test)))\n",
    "\n",
    "cm = confusion_matrix(y_test, resultXGB)\n",
    "%matplotlib inline\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae7afb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff52612",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
