{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41e9a24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Expand jupyter cell to complete view in high resolution monitor\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45697c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 categorical features: \n",
      "\n",
      "There are 66 numerical features: \n",
      "\n",
      "Cantidad de muestras originales de entrenamiento\n",
      "0    134568\n",
      "1      1816\n",
      "Name: Y, dtype: int64\n",
      "Cantidad de muestras reservadas para testeo de clase 1\n",
      "320\n",
      "Cantidad de muestras por clase después de realizar oversampling\n",
      "0    134568\n",
      "1     20185\n",
      "Name: Y, dtype: int64\n",
      "Cantidad de muestras por clase después de realizar undersampling\n",
      "0    67283\n",
      "1    20185\n",
      "Name: Y, dtype: int64\n",
      "Split de datos de entrenamiento y testeo\n",
      "\tTrain:  61227\n",
      "\tTest:  26241\n",
      "Split de datos de entrenamiento y testeo al agregar datos de clase 1 nuevos\n",
      "\tTrain:  61227\n",
      "\tTest:  26561\n"
     ]
    }
   ],
   "source": [
    "# https://towardsdatascience.com/how-to-use-sklearn-pipelines-for-ridiculously-neat-code-a61ab66ca90d \n",
    "# Pipeline and gridsearch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from numpy import genfromtxt\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import RobustScaler, Normalizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample\n",
    "import imblearn\n",
    "from imblearn.under_sampling import (ClusterCentroids, RandomUnderSampler, OneSidedSelection,  NeighbourhoodCleaningRule, InstanceHardnessThreshold, AllKNN, NearMiss)\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTEN, SMOTE, ADASYN, BorderlineSMOTE\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import statsmodels.api as sm\n",
    "import pylab\n",
    "from scipy import stats\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "                                                                            # df refers to data frame\n",
    "                                                                            # add here the new data extracted for validation purposes\n",
    "#df_raw_test = pd.read_csv('C:\\\\Users\\\\kevinmor\\\\OneDrive - Intel Corporation\\\\Desktop\\\\Full Time\\\\AFE AI Assesment\\\\CSE\\\\testdataset.csv')\n",
    "                                                                            # volume raw data for further prediction model testing purposes\n",
    "\n",
    "df = pd.read_csv('C:\\\\Users\\\\kevinmor\\\\OneDrive - Intel Corporation\\\\Desktop\\\\Full Time\\\\AFE AI Assesment\\\\CSE\\\\afe_cold_5430_train_minus15.csv')\n",
    "                                                                            # dataset with unseen class 1 examples\n",
    "df_test = pd.read_csv('C:\\\\Users\\\\kevinmor\\\\OneDrive - Intel Corporation\\\\Desktop\\\\Full Time\\\\AFE AI Assesment\\\\CSE\\\\afe_cold_5430_test_15.csv')\n",
    "\n",
    "                                                                            # there is pending to automate column removal, for example when one column has just one value (it does not contribute with valuable information)\n",
    "\n",
    "                                                                            # split features and output of test dataset\n",
    "y_t = df_test.Y\n",
    "X_t = df_test.drop('Y',axis=1)\n",
    "                                                                            # split features and output of training dataset\n",
    "y = df.Y\n",
    "X = df.drop('Y',axis=1)\n",
    "\n",
    "                                                                            # X and y contain original dataset\n",
    "                                                                            # confirm that there are not categorical features          \n",
    "categorical_features = X.select_dtypes(exclude='number').columns.tolist()\n",
    "print(f'There are {len(categorical_features)} categorical features:', '\\n')\n",
    "                                                                            # obtain numerical features\n",
    "numerical_features = X.select_dtypes(include='number').columns.tolist()\n",
    "print(f'There are {len(numerical_features)} numerical features:', '\\n')\n",
    "#print(numerical_features)\n",
    "                                                                            # X_cc and y_cc will contain preprocessed data\n",
    "                                                                            # u refers to unprocessed \n",
    "X_ccu, y_cc = X, y\n",
    "print(\"Cantidad de muestras originales de entrenamiento\")\n",
    "print(df['Y'].value_counts())  \n",
    "\n",
    "\n",
    "print(\"Cantidad de muestras reservadas para testeo de clase 1\")\n",
    "print(len(X_t))\n",
    "\n",
    "                                                                            # oversampling or boostering    \n",
    "                                                                            # https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/\n",
    "                                                                            # the minority class would have, in this case, the sampling_strategy*100 percentaje of the majority class examples\n",
    "                                                                            # https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html#imblearn.over_sampling.RandomOverSampler.fit_resample\n",
    "                                                                        \n",
    "# Minority class proportion\n",
    "ONm= 15\n",
    "# Mayority class proportion\n",
    "ONM= 100\n",
    "ratioOverSampling= ONm/ONM\n",
    "\n",
    "# SMOTE and ADASYN generate new samples in by interpolation\n",
    "# When dealing with a mixed of continuous and categorical features, SMOTENC is the only method which can handle this case.\n",
    "# ADASYN will focus on the samples which are difficult to classify with a nearest-neighbors rule while regular SMOTE will not make any distinction\n",
    "# https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTEN.html#imblearn.over_sampling.SMOTEN\n",
    "# number of nearest neighbours to used to construct synthetic samples\n",
    "# https://imbalanced-learn.org/stable/auto_examples/over-sampling/plot_comparison_over_sampling.html\n",
    "oversamplers = [RandomOverSampler(sampling_strategy=ratioOverSampling), SMOTEN(random_state=17, sampling_strategy=ratioOverSampling, n_jobs=-1, k_neighbors=5), BorderlineSMOTE(random_state=0, kind=\"borderline-1\") ]\n",
    "oversample = oversamplers[0]\n",
    "                                                                            # fit and apply the transform\n",
    "X_ccu, y_cc = oversample.fit_resample(X_ccu, y_cc)\n",
    "print(\"Cantidad de muestras por clase después de realizar oversampling\")\n",
    "print(y_cc.value_counts())\n",
    "\n",
    "#Under-sampling: Cluster Centroids\n",
    "# Minority class proportion\n",
    "Nm= 30\n",
    "# Mayority class proportion\n",
    "NM= 100\n",
    "ratioUnderSampling= Nm/NM\n",
    "\n",
    "# Compare undersamplers\n",
    "# https://imbalanced-learn.org/stable/auto_examples/under-sampling/plot_comparison_under_sampling.html#sphx-glr-auto-examples-under-sampling-plot-comparison-under-sampling-py\n",
    "samplers= [ClusterCentroids(sampling_strategy=ratioUnderSampling), \n",
    "           InstanceHardnessThreshold(estimator=LogisticRegression(),random_state=0),\n",
    "           OneSidedSelection(random_state=0), \n",
    "           NeighbourhoodCleaningRule(),\n",
    "           AllKNN(allow_minority=True),\n",
    "           NearMiss(version=1, sampling_strategy=ratioUnderSampling, n_jobs=-1), \n",
    "           NearMiss(version=2, sampling_strategy=ratioUnderSampling, n_jobs=-1), \n",
    "           NearMiss(version=3, n_neighbors_ver3=3, n_jobs=-1)]\n",
    "                                                                            # undersampling\n",
    "                                                                            # https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/\n",
    "#undersample = RandomUnderSampler(sampling_strategy=1)\n",
    "                                                                            # fit and apply the transform\n",
    "#X_cc, y_cc = undersample.fit_resample(X_cc, y_cc)\n",
    "cc = samplers[5]\n",
    "X_ccu, y_cc = cc.fit_resample(X_ccu, y_cc)\n",
    "                                                                            # summarize class distribution\n",
    "print(\"Cantidad de muestras por clase después de realizar undersampling\")\n",
    "print(y_cc.value_counts())\n",
    "                                                                            # Combining over/under-sampling can result in improved overall performance compared to performing one or the other techniques in isolation.\n",
    "                                                                            # split data into train and test subsets\n",
    "                                                                            # altough class 0 test examples are new to the AI models that are going to be trained, class 1 examples are not new, this because of the oversampling strategy followed.\n",
    "                                                                            # due to the reproduction of class 1 examples, at test dataset, there are \"seen\" examples for the neuronal networks, so there are needed real new examples, this is the\n",
    "                                                                            # intend of X_t examples.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ccu, y_cc, train_size=0.7, random_state=17)\n",
    "print(\"Split de datos de entrenamiento y testeo\")\n",
    "print(\"\\tTrain: \", len(X_train))\n",
    "print(\"\\tTest: \", len(X_test))\n",
    "                                                                            # add 321 (15 % of original class 1) unseen class 1 examples\n",
    "X_test=np.append(X_test, X_t, axis=0)\n",
    "y_test=np.append(y_test, y_t, axis=0)\n",
    "print(\"Split de datos de entrenamiento y testeo al agregar datos de clase 1 nuevos\")\n",
    "print(\"\\tTrain: \", len(X_train))\n",
    "print(\"\\tTest: \", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de6f1cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1. ,  0. ,  1. , ..., -1. ,  3.5,  0. ],\n",
       "       [-0.5,  0. ,  0. , ...,  1.4,  0. ,  0. ],\n",
       "       [ 0.5,  0. ,  1. , ..., -0.6,  2.5,  0. ],\n",
       "       ...,\n",
       "       [ 0. ,  0. ,  0. , ..., -1.2,  0.5,  0. ],\n",
       "       [ 0. ,  0. ,  0. , ..., -1. ,  0. ,  1. ],\n",
       "       [ 0.5,  0. ,  1. , ..., -0.2,  0. ,  0. ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "                                                            # https://towardsdatascience.com/how-to-use-sklearn-pipelines-for-ridiculously-neat-code-a61ab66ca90d\n",
    "                                                            # Define preprocessing for data\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    ('scale', RobustScaler())\n",
    "    ])\n",
    "                                                            # pipeline objects have fit and transform methods\n",
    "numeric_pipeline.fit_transform(X_train.select_dtypes(include='number'))\n",
    "                                                            # define scaler for numerical features                                                            \n",
    "full_processor = ColumnTransformer(transformers=[\n",
    "    ('number', numeric_pipeline, numerical_features)\n",
    "    ])\n",
    "# apply transformation\n",
    "full_processor.fit_transform(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a69ea227",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21044/1825566650.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# Fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best score:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#GridSearchCV for tunning model\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# https://towardsdatascience.com/binary-classification-xgboost-hyperparameter-tuning-scenarios-by-non-exhaustive-grid-search-and-c261f4ce098d\n",
    "# https://xgboost.readthedocs.io/en/stable/tutorials/param_tuning.html\n",
    "# https://blog.cambridgespark.com/hyperparameter-tuning-in-xgboost-4ff9100a3b2f\n",
    "# https://machinelearningmastery.com/xgboost-for-imbalanced-classification/\n",
    "# https://xgboost-clone.readthedocs.io/en/latest/parameter.html#learning-task-parameters\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "# https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/\n",
    "\n",
    "#  scale_pos_weight is the ratio of number of negative class to the positive class (0.7)\n",
    "# \"subsample\" is the fraction of the training samples (randomly selected) that will be used to train each tree.\n",
    "# \"colsample_by_tree\" is the fraction of features (randomly selected) that will be used to train each tree.\n",
    "# \"colsample_bylevel\" is the fraction of features (randomly selected) that will be used in each node to train each tree.\n",
    "# A smaller min_child_weight allows the algorithm to create children that correspond to fewer samples, thus allowing for more complex trees, but again, more likely to overfit.\n",
    "\n",
    "# 3888 experiments\n",
    "param_grid = {'gamma': [ 0.35],\n",
    "              'eta': [0.15],\n",
    "              'max_depth': [40],\n",
    "              'n_estimators': [200],\n",
    "              'reg_alpha': [ 0.15],\n",
    "              'reg_lambda': [0.15],\n",
    "              'colsample_bytree': [0.95],\n",
    "              'colsample_bylevel': [0.95],\n",
    "              'min_child_weight': [10],\n",
    "              'scale_pos_weight': [0.72]}\n",
    "\n",
    "\n",
    "\n",
    "# Init classifier\n",
    "xgb_cl = xgb.XGBClassifier(objective=\"binary:logistic\")\n",
    "\n",
    "# Init Grid Search\n",
    "grid_cv = GridSearchCV(xgb_cl, param_grid, n_jobs=-1, cv=3, scoring=\"f1\")\n",
    "\n",
    "# Fit\n",
    "_ = grid_cv.fit(X_train, y_train)\n",
    "\n",
    "print('Best score:', abs(grid_cv.best_score_))\n",
    "print('Best alpha:', grid_cv.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "196ff11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevinmor\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:47:30] WARNING: D:\\bld\\xgboost-split_1643227225381\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy for XGBoost: 0.934979857686081\n",
      "F1_Score for XGBoost: 0.8491834774255522\n",
      "Precision_Score for XGBoost: 0.7561430793157076\n",
      "Recall_Score for XGBoost: 0.9683330013941446\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fill with the best parameters found\n",
    "# RUN THIS\n",
    "\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', colsample_bytree = 0.95, colsample_bylevel = 0.95, eta = 0.15, gamma = 0.35, max_depth = 40, n_estimators = 200, reg_alpha = 0.15, reg_lambda = 0.15, min_child_weight = 10, scale_pos_weight = 0.72)\n",
    "\n",
    "\n",
    "xgb_cl.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "resultXGB = xgb_cl.predict(X_test)\n",
    "\n",
    "# Score\n",
    "#accuracy_score(y_test, preds)\n",
    "print(\"Accuracy for XGBoost: \" + str(accuracy_score(resultXGB, y_test)))\n",
    "print(\"F1_Score for XGBoost: \" + str(f1_score(resultXGB, y_test)))\n",
    "print(\"Precision_Score for XGBoost: \" + str(precision_score(resultXGB, y_test)))\n",
    "print(\"Recall_Score for XGBoost: \" + str(recall_score(resultXGB, y_test)))\n",
    "\n",
    "cm = confusion_matrix(y_test, resultXGB)\n",
    "%matplotlib inline\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
